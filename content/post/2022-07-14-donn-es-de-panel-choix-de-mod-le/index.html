---
title: Données de panel choix de modèle
author: Ludovic Vigneron
date: '2022-07-14'
slug: []
categories:
  - r
  - Panel
tags:
  - R
  - panel
---



<p><strong>Entamer l’écriture un nouveau papier est l’occasion de revenir sur des méthodes que j’ai déjà utiliser et d’en découvrir de nouvelles. J’en profites pour réviser et partager quelques réflexions techniques. Il s’agit de travailler des données des panels. Bon rien d’original ici. La grande majorité de mes travaux utilisent ce type d’informations notamment au travers de modèles à effets fixes. Le défaut de la méthode est qu’elle nécessite que l’ensemble des informations traitées varies à la fois entre les individus et dans le temps. Une solution que je viens de découvrir au fil des lectures pour mobiliser en complément des variables fixes dans l’analyse est de passer par des modèles hybrides de type between-within. Ceux-ci sont développés par <a href="https://methods.sagepub.com/book/fixed-effects-regression-models/d33.xml">Allison (2009)</a> et <a href="https://www.cambridge.org/core/journals/political-science-research-and-methods/article/explaining-fixed-effects-random-effects-modeling-of-timeseries-crosssectional-and-panel-data/0334A27557D15848549120FE8ECD8D63#article">Bell et Jones (2015)</a>. Mais avant d’entamer leur analyse, débutons une série de postes pour revenir sur quelques basiques concernant les données des panels.</strong></p>
<p>Pour commencer, chargeons quelques packages: le <strong>tidyverse</strong>, <strong>broom</strong>, qui permet de gérer les estimations de modèle comme des tibbles, <strong>plm</strong>, qui permet d’estimer les modèles de panel classiques, et <strong>panelr</strong>, qui permet notamment d’estimer les modèles hybrides.</p>
<pre class="r"><code>library(tidyverse)
library(broom)
library(DT)
library(plm)
library(panelr)
library(lmtest) </code></pre>
<p>Chargeons également un jeu de données afin de réaliser nos différentes expérimentations. Utilisons le jeu <em>WageData</em> qui est inclus dans <strong>panelr</strong>.</p>
<pre class="r"><code>wages&lt;-WageData
glimpse(wages)</code></pre>
<pre><code>## Rows: 4,165
## Columns: 14
## $ exp   &lt;dbl&gt; 3, 4, 5, 6, 7, 8, 9, 30, 31, 32, 33, 34, 35, 36, 6, 7, 8, 9, 10,…
## $ wks   &lt;dbl&gt; 32, 43, 40, 39, 42, 35, 32, 34, 27, 33, 30, 30, 37, 30, 50, 51, …
## $ occ   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
## $ ind   &lt;dbl&gt; 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0…
## $ south &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
## $ smsa  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1…
## $ ms    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0…
## $ fem   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1…
## $ union &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0…
## $ ed    &lt;dbl&gt; 9, 9, 9, 9, 9, 9, 9, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12,…
## $ blk   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1…
## $ lwage &lt;dbl&gt; 5.56068, 5.72031, 5.99645, 5.99645, 6.06146, 6.17379, 6.24417, 6…
## $ t     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1…
## $ id    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4…</code></pre>
<p>La base comprend 4 165 observations sur 14 variables. Deux d’entre-elles structurent l’ensemble id, identifiant des individus sur lesquels l’information est collectée, et t, qui marque la date de cette collecte.</p>
<pre class="r"><code>paste(&#39;On a&#39;,length(unique(wages$id)),&#39;individus&#39;)</code></pre>
<pre><code>## [1] &quot;On a 595 individus&quot;</code></pre>
<pre class="r"><code>paste(&#39;observés sur&#39;,length(unique(wages$t)),&#39;périodes&#39;)</code></pre>
<pre><code>## [1] &quot;observés sur 7 périodes&quot;</code></pre>
<pre class="r"><code>paste(&#39;soit&#39;,595*7,&#39;observations&#39;)</code></pre>
<pre><code>## [1] &quot;soit 4165 observations&quot;</code></pre>
<p>Le panel est cylindré. La variable que l’on va expliquer ici est lwage, le log du salaire sur la période. Elle sera reprise par la suite comme <span class="math inline">\(y_{it}\)</span>. Voyons à quoi ressemble sa distribution.</p>
<pre class="r"><code>wages %&gt;% 
  summarise(min_=min(lwage),
            Prem_Q=quantile(lwage,probs=0.25),
            median_=median(lwage),
            Trois_Q=quantile(lwage,probs=0.75),
            max_=max(lwage),
            mean_=mean(lwage),
            sd_=sd(lwage))</code></pre>
<pre><code>##      min_  Prem_Q median_ Trois_Q  max_    mean_       sd_
## 1 4.60517 6.39526 6.68461 6.95273 8.537 6.676346 0.4615122</code></pre>
<p>On a quelque chose proche d’une loi normale. L’hétérogénéité des situations est ici marquée par l’écart type. Cette hétérogénéité a deux sources : la variation des situations individuelles au travers le temps (variance intra-individuelle) et les différences de situations individuelles indépendantes du temps (variance inter-individuelle).</p>
<p>Pour s’en donner une idée, présentons deux graphes s’organisant sur le même principe. On présente la moyenne de la variable expliquée (lwage) et son intervalle de confiance à 95% calculés en fonction du découpage suivi. Pour la premier, consacré à la variation intra-individuelle, le calcule s’opère pour tout les individus (595) sur chaque période.</p>
<pre class="r"><code>het_gr &lt;- function(df, var1, var2, titre,mx_){
  var1 &lt;-  enquo(var1); var2 &lt;-  enquo(var2);
  df_&lt;-df %&gt;% group_by(!!var1) %&gt;% 
              summarise(mean_=mean(!!var2),
                        bas=t.test(!!var2)$conf.int[1],
                        haut=t.test(!!var2)$conf.int[2],
                        )
  ggplot(data=df_,aes(x=!!var1))+
    geom_point(aes(y=mean_),color=&#39;red&#39;)+
    geom_line(aes(y=mean_),color=&#39;red&#39;,size=0.5)+
    geom_segment(aes(xend=!!var1,x=!!var1,yend=haut,y=bas))+
    labs(title=titre)+
    scale_x_continuous(breaks=mx_)+
    theme_minimal()+
    theme(plot.title = element_text(hjust=0.5))}
het_gr (df = wages, var1 = t, var2 = lwage,
        titre=&#39;Hétérogénéité entre les périodes&#39;,mx_=1:7)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>On voit ici une nette tendance haussière des salaires sur la période d’étude. Le second graphe s’établit sur une base individuel. Les calculs sont fait sur chaque individu (id) pour la période d’étude (7).</p>
<pre class="r"><code>het_gr (df = wages, var1 = id, var2 = lwage,
        titre=&#39;Hétérogénéité entre les individus&#39;,mx_=seq(0,600,50))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>L’ordre des individus est celui de leur identifiant. Celui-ci est assigné de manière aléatoire. Il n’y a donc pas de tendance qui se dégage. On peut néanmoins observer la variabilité inter-individuelle.</p>
<p>Ceci étant observé, intéressons-nous à la manière dont le nombre de semaines travaillées (wks) influence le salaire (lwage). Cette variable explicative sera nommée de manière générale <span class="math inline">\(x_{it}\)</span>. Le premier réflexe que l’on a souvent est d’ignorer la décomposition de l’hétérogéniété et d’estimer simplement un modèle linéaire classique.</p>
<p><span class="math display">\[y_{it}=\alpha+\beta_{1}.x_{it}+u_{it}\]</span></p>
<p>Ce type de modèle utilisé sur de données de panel est appelé <strong>modèle de pooling</strong>. Estimons-le avec la fonction <em>lm()</em>.</p>
<pre class="r"><code>lm(lwage~wks,data=wages) %&gt;% tidy() </code></pre>
<pre><code>## # A tibble: 2 × 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)  6.43      0.0656      98.1  0       
## 2 wks          0.00527   0.00139      3.78 0.000157</code></pre>
<p>Le même résultat est obtenu avec la fonction plm() du package du même nom. Précisons y les variables indexant les individus et les périodes.</p>
<pre class="r"><code>g &lt;- plm(lwage ~ wks, data=wages, index=c(&quot;id&quot;),model=&quot;pooling&quot;)
g %&gt;% tidy()</code></pre>
<pre><code>## # A tibble: 2 × 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)  6.43      0.0656      98.1  0       
## 2 wks          0.00527   0.00139      3.78 0.000157</code></pre>
<p>Quel que soient la fonction d’estimation utilisée, il s’agit de résumer l’information contenu dans le nuage de points (noirs) à partir de la droite (en rouge) dont nous venons trouver les paramètres.</p>
<pre class="r"><code>ggplot(data=wages,aes(x=wks,y=lwage))+
  geom_point()+
  geom_smooth(method = &quot;lm&quot;,color=&#39;red&#39;,se=FALSE)+
  coord_cartesian(expand=FALSE,xlim=c(4,53),ylim=c(4.5,8.7))+
  theme_minimal()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>cette approche est appropriée si l’erreur <span class="math inline">\(u_{it}\)</span> est indépendante à la fois du régresseur <span class="math inline">\(x_{it}\)</span> et de sa composante individuelle de l’erreur <span class="math inline">\(\gamma_i\)</span> (et/ou sa composante temporelle <span class="math inline">\(\mu_t\)</span>). Dans le cas contraire, l’estimateur de MCO est inconsistant.</p>
<p>Qu’est-ce que cela signifie d’un point de vue pratique? Simplement que le coefficient estimé via le pooling n’est pas différent (statistiquement) des coefficients estimés sur des bases réduites à chaque individu. Pour le savoir, on procède à un test de Chow (test de stabilité basé sur la statistique de Fisher proposé par Baltagi 2005). Le package <em>plm</em> offre des éléments pour réaliser la procédure. Il y a tout d’abord la fonction <strong>pvcm()</strong> qui permet de générer les estimations des modèles individus par individus (within intra-individuel).</p>
<pre class="r"><code>g_i &lt;- pvcm(lwage~wks, data=wages,index=&quot;id&quot;, model=&quot;within&quot;)
g_i$coefficients</code></pre>
<pre><code>##      (Intercept)           wks
## 1     6.14989081 -0.0049274732
## 2     6.08755497  0.0130146410
## 3     7.20968390 -0.0138614645
## 4     6.83821263 -0.0094290406
## 5     5.72935355  0.0250000159
## 6     7.88249474 -0.0172180494
## 7     5.97743961  0.0070516696
## 8     6.24174502  0.0070614851
## 9    10.84427255 -0.0822307666
## 10    7.33514128 -0.0190131993
## 11    7.25796319 -0.0077695010
## 12   11.65899458 -0.1047381401
## 13    9.83399029 -0.0559338093
## 14   18.17760098 -0.2518697977
## 15    7.84239206 -0.0356671094
## 16    4.29368141  0.0354460290
## 17    8.65015096 -0.0369461967
## 18  -13.13942541  0.4387350082
## 19    6.99398037 -0.0080298739
## 20   16.57310120 -0.1957357725
## 21    7.02407124 -0.0175756328
## 22    4.27504977  0.0539047305
## 23   16.80931434 -0.1875740784
## 24    5.09756516  0.0118689640
## 25    4.10394568  0.0678508470
## 26   14.34180423 -0.1540274819
## 27    7.70950049 -0.0168825585
## 28    9.49601765 -0.0555551529
## 29  -13.63428799  0.4261501630
## 30    6.10757738  0.0064075095
## 31   11.95346898 -0.1001780159
## 32   22.00555878 -0.3007556686
## 33    7.41367858 -0.0045161247
## 34    3.25455285  0.0565206543
## 35    6.61369377  0.0029800121
## 36    8.38067024 -0.0290898283
## 37    7.34055551 -0.0051238802
## 38    2.35446596  0.0812716484
## 39    3.44799170  0.0639651255
## 40    5.95614292  0.0188185266
## 41   15.12406130 -0.1575048403
## 42    5.13984707  0.0334806235
## 43   10.16666356 -0.0653142496
## 44   19.12017020 -0.2522067229
## 45    4.06662064  0.0484099865
## 46    3.80301778  0.0557713177
## 47   12.14663758 -0.1061351299
## 48    8.41747996 -0.0262463030
## 49   -5.52524614  0.2740490437
## 50    7.40084303 -0.0200108261
## 51    8.10138671 -0.0123576058
## 52    2.24456440  0.1044291953
## 53    4.34212181  0.0545724630
## 54    7.09376900 -0.0058717849
## 55   13.21740543 -0.1309101428
## 56    7.51686519 -0.0230716644
## 57    6.71965342 -0.0080611986
## 58    5.97584095  0.0191670615
## 59   16.33852037 -0.1898843447
## 60    5.94443239  0.0031540259
## 61    7.03702544 -0.0034471064
## 62   22.99713178 -0.3235075871
## 63   16.97090024 -0.1951266726
## 64    4.35537282  0.0466317960
## 65    7.52818035 -0.0162806593
## 66    9.47515449 -0.0605955573
## 67   12.28864336 -0.1219141483
## 68    4.98385819  0.0376739909
## 69    6.52212987  0.0030605435
## 70   18.02609110 -0.2325091362
## 71   11.51234191 -0.0936183135
## 72    4.66125669  0.0511979342
## 73   15.02966336 -0.1716117064
## 74    6.09615461 -0.0083456337
## 75    5.79040587  0.0081557385
## 76   11.90963071 -0.1249065919
## 77    6.74941295 -0.0166132483
## 78    3.87375904  0.0444176322
## 79    6.28874358 -0.0116436054
## 80    1.06324673  0.1183748643
## 81   -4.55565442  0.2342631400
## 82    7.53100833 -0.0151002170
## 83    6.28299660  0.0017671317
## 84    7.01973833 -0.0083646282
## 85   10.66206630 -0.0854917407
## 86    5.34904204  0.0281613379
## 87    6.22400492  0.0135323901
## 88   11.42341082 -0.0967790365
## 89   -0.70394576  0.1455451449
## 90   -0.09316659  0.1344854832
## 91    6.07065090  0.0167891340
## 92    6.50015866  0.0043364607
## 93    7.13430252 -0.0166564242
## 94    6.32232909  0.0178683281
## 95    6.46539484  0.0015669709
## 96   24.43048680 -0.3468575875
## 97    5.11483484  0.0276652284
## 98    9.99463749 -0.0578413010
## 99    7.85609684 -0.0391941847
## 100   3.50540362  0.0569105032
## 101   7.19356748 -0.0055828311
## 102  17.26858759 -0.2082520723
## 103   4.70774188  0.0509201303
## 104  11.27837058 -0.1062460423
## 105  11.49030959 -0.0954261285
## 106   9.07101059 -0.0500454903
## 107   8.86267184 -0.0371914883
## 108   6.11027812  0.0099790611
## 109   9.03727158 -0.0413224300
## 110   6.59878832  0.0028905706
## 111   3.01631308  0.0717511408
## 112  12.87629542 -0.1193095759
## 113   6.56041803  0.0173978701
## 114   8.18260026 -0.0360434055
## 115  20.09284019 -0.2683447997
## 116  10.65606415 -0.0757517394
## 117   6.76177804 -0.0010436220
## 118   6.68642529  0.0023111220
## 119   7.35573254  0.0091052306
## 120  21.66241918 -0.2998099804
## 121  15.85640335 -0.1722745895
## 122   2.95212829  0.0803440809
## 123   7.65451224 -0.0215603163
## 124  15.77456831 -0.1747554050
## 125   4.96614180  0.0330117977
## 126   6.58265874 -0.0023661728
## 127   8.14532248 -0.0212504853
## 128   5.90037072  0.0094043412
## 129  -2.35152340  0.1766331991
## 130  -4.83123899  0.2523615360
## 131   9.50819963 -0.0644154249
## 132  12.25628167 -0.0982129285
## 133   8.87989088 -0.0451912789
## 134   3.22294052  0.0600310167
## 135  17.85172374 -0.2257788897
## 136  12.36964809 -0.1051262113
## 137  -4.76798725  0.2374599457
## 138   8.32489664 -0.0204052014
## 139  18.84165613 -0.2383910606
## 140   6.66460535 -0.0014927746
## 141   2.45414831  0.0771817957
## 142   4.77613006  0.0442699965
## 143  19.76169614 -0.2684919437
## 144  23.75437942 -0.3509619474
## 145 -13.15362120  0.4151633581
## 146   7.15407133            NA
## 147   2.89580834  0.0836991668
## 148   1.65120680  0.0967883709
## 149   4.68653663  0.0576941172
## 150   6.84969840 -0.0055486822
## 151   9.00790764 -0.0502008079
## 152   5.76153250 -0.0056223147
## 153   6.37415655  0.0009265132
## 154   6.16865801  0.0154954773
## 155   5.90821136  0.0218353131
## 156  -6.50949065  0.2825738986
## 157   5.22698084  0.0294304729
## 158  -5.04888614  0.2540751298
## 159   8.46252777 -0.0372912253
## 160   8.81835750 -0.0497928814
## 161   8.62387837 -0.0414953894
## 162   5.35084225  0.0181532774
## 163  11.49275841 -0.1030874252
## 164   8.56097753 -0.0464188462
## 165   7.64400538 -0.0252184914
## 166   8.39660731 -0.0295330378
## 167   4.81358961  0.0188506662
## 168  -1.24511294  0.1840307827
## 169   3.10269165  0.0839046836
## 170   4.46123440  0.0305086826
## 171   7.06682826 -0.0188261294
## 172   4.51870437  0.0563566246
## 173  10.03358416 -0.0580080227
## 174   5.54725369  0.0269953605
## 175   6.10914419  0.0031775236
## 176  15.73147350 -0.1796624396
## 177   0.77655385  0.1175140835
## 178   6.71134977 -0.0068289757
## 179   4.03557062  0.0420674880
## 180  -8.27125587  0.3027925403
## 181   6.82256666  0.0045318728
## 182  11.73802900 -0.1127549807
## 183   4.85530128  0.0174134125
## 184   6.79442576            NA
## 185  13.22938589 -0.1353458475
## 186   8.36719230 -0.0281513901
## 187   7.16893101 -0.0029876242
## 188  13.38862015 -0.1360827873
## 189   5.81668873  0.0247852325
## 190  22.18619618 -0.3116569042
## 191   7.83569359 -0.0308600143
## 192   6.72421000 -0.0019705208
## 193   4.80726189  0.0496898453
## 194   7.93691022 -0.0252850056
## 195  11.15639155 -0.0877507611
## 196   7.76237518 -0.0261513384
## 197   7.61247528 -0.0347138619
## 198  12.69892389 -0.1262680054
## 199   8.76351053 -0.0412924164
## 200   7.96749900 -0.0399452002
## 201  12.06490672 -0.1197267373
## 202   7.45968399 -0.0257449945
## 203   6.32267981 -0.0045392036
## 204   7.06148653 -0.0079308517
## 205   7.35888350 -0.0131847878
## 206  15.05180442 -0.1583072543
## 207   5.92472804  0.0281965909
## 208   5.27033013  0.0111579313
## 209   7.68678999 -0.0228469555
## 210   6.42758554  0.0077674432
## 211   4.18085553  0.0620454111
## 212   7.27049820 -0.0019669349
## 213   7.40132678 -0.0071573059
## 214   1.43909454  0.1024015745
## 215   5.08277643  0.0230481711
## 216  15.13803966 -0.1658907303
## 217   5.17270923  0.0218550165
## 218   6.24892148  0.0057435757
## 219   3.45550644  0.0762482249
## 220   3.20993088  0.0827477195
## 221   7.94043815 -0.0168402390
## 222   3.45583496  0.0568393127
## 223  16.54365116 -0.2056941390
## 224   6.60197898  0.0125798375
## 225   6.47466714            NA
## 226   7.55290242 -0.0341640436
## 227   8.04889950 -0.0233619953
## 228  32.93573014 -0.5229083697
## 229   5.47564475  0.0333050092
## 230   6.49906009            NA
## 231  19.32272220 -0.2420998414
## 232   3.83742713  0.0664132690
## 233   7.92884348 -0.0220832339
## 234   5.18340633  0.0275765025
## 235   6.81316469 -0.0154580465
## 236  16.46279013 -0.1911600033
## 237   5.81948054  0.0143039185
## 238   8.81630729 -0.0378674865
## 239  -4.66364010  0.2595673402
## 240  25.79346228 -0.3799165090
## 241   7.30553575 -0.0125150327
## 242   7.00702629 -0.0240878588
## 243   5.77099986  0.0309490316
## 244   5.47363362  0.0224086200
## 245   6.59547015 -0.0001946501
## 246   6.14833355  0.0090535896
## 247   4.83412504  0.0177810033
## 248   4.04554370  0.0361614207
## 249  13.39778900 -0.1375539780
## 250  -4.51494209  0.2260466417
## 251  15.46349708 -0.1832492749
## 252   6.35126344  0.0221765462
## 253   6.64136529 -0.0001136228
## 254   6.98421401 -0.0108810540
## 255   5.91961124  0.0103503238
## 256   5.86375272  0.0191927522
## 257   6.91043711            NA
## 258   6.14905073  0.0113320451
## 259   6.34222405 -0.0051204459
## 260  17.71993799 -0.2212395191
## 261   6.38319499  0.0058737104
## 262   0.25925173  0.1387100220
## 263   5.13436165  0.0293274967
## 264   6.24063618  0.0073600237
## 265   6.98747187 -0.0009327109
## 266   6.50850303  0.0138293224
## 267  14.55318546 -0.1612711549
## 268   9.47626148 -0.0643601418
## 269   8.96251160 -0.0412754416
## 270  22.34033199 -0.3066473282
## 271   6.66625854            NA
## 272  -1.14776234  0.1596630170
## 273   6.95474176 -0.0063481535
## 274  13.61192596 -0.1389041344
## 275   5.81193924  0.0155092880
## 276   7.57907822 -0.0165364469
## 277  12.15413223 -0.1155099869
## 278  13.62739801 -0.1306833625
## 279   9.48693023 -0.0529599190
## 280   6.63879553 -0.0093492951
## 281   5.86816692  0.0184806621
## 282   9.88856629 -0.0617012664
## 283  33.73219969 -0.5354514837
## 284   5.48203421  0.0233005927
## 285   6.52023574  0.0046274861
## 286   3.08996060  0.0729846578
## 287   7.43841313 -0.0158716897
## 288  11.28420797 -0.0869753433
## 289  34.93342180 -0.5584861994
## 290  11.31784606 -0.0990015864
## 291   6.11813320  0.0161391894
## 292   4.63916516  0.0463449955
## 293   5.34411788  0.0240664085
## 294   6.48641528 -0.0008019364
## 295  15.27659891 -0.1800491611
## 296   6.49354261  0.0005006085
## 297   6.55729464  0.0021528589
## 298   7.32330069 -0.0185129826
## 299  -3.35906315  0.1973261833
## 300   9.39935613 -0.0617291927
## 301  11.59451980 -0.1004205315
## 302   8.38741895 -0.0497278770
## 303  21.97465613 -0.3116054416
## 304  -6.43869336  0.2520400683
## 305  12.99809206 -0.1206314762
## 306  -0.40888262  0.1401772499
## 307   5.06053691  0.0339242312
## 308   9.65214140 -0.0643704781
## 309   6.02210717  0.0026456520
## 310   6.31668750  0.0058543858
## 311   6.71402179  0.0002597746
## 312   5.89194972  0.0190543182
## 313  15.88637223 -0.1914612486
## 314   4.97741600  0.0325127144
## 315   4.85808084  0.0375450156
## 316  24.20561171 -0.3329896927
## 317   6.60249331 -0.0074694221
## 318   6.66371246 -0.0007313941
## 319   8.45487388 -0.0372221548
## 320   9.87181273 -0.0709842484
## 321  10.61646428 -0.0858391615
## 322  11.70678261 -0.0994949341
## 323  10.83335622 -0.0825634797
## 324   6.01869353  0.0171173185
## 325   6.46162435            NA
## 326  21.59027243 -0.3133165042
## 327   6.85292595 -0.0170909477
## 328   0.08401717  0.1386770285
## 329  19.30617881 -0.2629501820
## 330   7.63387475 -0.0194491580
## 331   6.17022414  0.0178165257
## 332   5.13977308  0.0170430517
## 333   7.87818708 -0.0241249084
## 334   6.05040851  0.0027776550
## 335   5.82514939  0.0188264047
## 336   7.49213272 -0.0182667602
## 337   8.23699983 -0.0251174238
## 338  21.70936980 -0.3202349345
## 339   9.74274278 -0.0759924274
## 340   6.27211592  0.0121600611
## 341  -5.90191638  0.2727734645
## 342  15.54176941 -0.1824478626
## 343   8.65462626 -0.0328898570
## 344   2.83175229  0.0953731090
## 345   6.69161582 -0.0056027174
## 346   9.05536220 -0.0515342615
## 347   7.15031242 -0.0046721101
## 348   8.54832331 -0.0206807778
## 349  21.00164809 -0.2877852201
## 350   5.54601756  0.0298482740
## 351   8.36970631 -0.0383671435
## 352  19.60363193 -0.2631917397
## 353  24.17021990 -0.3513078690
## 354   7.83041199 -0.0221195067
## 355  -2.79427281  0.1816292816
## 356  -6.74393868  0.2691166401
## 357   2.93435534  0.0792446293
## 358   8.22858103 -0.0423922504
## 359   6.49134299 -0.0066596602
## 360   7.16826419 -0.0025700895
## 361   6.24515070  0.0011907057
## 362  11.00768463 -0.0799817244
## 363   7.53385929 -0.0238216254
## 364  11.71016147 -0.1068047744
## 365  15.54292464 -0.1776992440
## 366   0.69639534  0.1184217082
## 367   6.79184126  0.0013934097
## 368  19.59589811 -0.2603404339
## 369  20.35618771 -0.2743968597
## 370  16.48566392 -0.1990414419
## 371  -9.83243815  0.3564716975
## 372  10.86738280 -0.0867475271
## 373   4.86940396  0.0299466848
## 374  12.25954857 -0.1246329308
## 375   7.55140858 -0.0398167740
## 376   5.80917005  0.0181870659
## 377   2.17191103  0.0970190693
## 378  12.59263849 -0.1146831512
## 379   0.28795872  0.1303106070
## 380  10.23211993 -0.0757321904
## 381   8.90450248 -0.0482696570
## 382   1.86867995  0.0926835170
## 383   6.88478851  0.0020244122
## 384   7.89041464 -0.0356268674
## 385   4.72328960  0.0434328730
## 386   0.85933526  0.1306784948
## 387   3.95902742  0.0565037508
## 388   9.75624202 -0.0596577571
## 389   6.20090466  0.0206010122
## 390  14.86879206 -0.1671795845
## 391   9.63375841 -0.0634953016
## 392   7.21251308 -0.0153342487
## 393   6.32162222  0.0088871167
## 394 -10.24913899  0.3359948794
## 395   6.23531979  0.0024322290
## 396   3.97569562  0.0493399739
## 397   4.04052741  0.0582973957
## 398  12.70726749 -0.1220272229
## 399   7.09108209 -0.0092808313
## 400   6.53716884  0.0052075998
## 401   6.29764332  0.0173162073
## 402   2.01196234  0.1022457073
## 403   7.19583852            NA
## 404   7.02016467 -0.0038662365
## 405  20.00798287 -0.2657800913
## 406   5.95595662  0.0150582844
## 407   8.82352014 -0.0358548199
## 408   7.09464871 -0.0176961018
## 409   4.82019357  0.0352839922
## 410   5.29121083  0.0154303043
## 411   9.70455864 -0.0673075020
## 412  11.09205627 -0.0859688520
## 413   5.78591251  0.0245498236
## 414   8.10561876 -0.0298949718
## 415   6.03295885  0.0036627594
## 416   3.64155910  0.0672272311
## 417   6.64180919 -0.0120308861
## 418  12.77961659 -0.1312515934
## 419   6.23005934  0.0132073552
## 420   9.64133539 -0.0613843386
## 421   5.71487024  0.0168545708
## 422  10.17935162 -0.0771529870
## 423   7.13297247 -0.0091652162
## 424   6.43007274  0.0135545066
## 425  24.06102711 -0.3577879942
## 426   8.80654348 -0.0446013980
## 427   3.76127647  0.0730394476
## 428   6.89159459 -0.0148843515
## 429   6.40172554  0.0057323615
## 430   4.02044391  0.0398237213
## 431   7.90454102 -0.0362292692
## 432   6.47995140  0.0125792588
## 433   6.59968424            NA
## 434   6.39910601  0.0099114865
## 435   5.89325304  0.0210383486
## 436   8.07006179 -0.0309546815
## 437   6.65855073 -0.0076522490
## 438   6.95340259 -0.0095590146
## 439   7.41506677 -0.0117627336
## 440  15.49175847 -0.1838048697
## 441   5.47718606  0.0184356010
## 442   9.94352911 -0.0744402467
## 443   1.11183898  0.1031506856
## 444   6.06294167  0.0179616037
## 445  12.28850918 -0.1338669777
## 446   8.69334918 -0.0560253607
## 447   2.63709445  0.0652486324
## 448   8.93992177 -0.0442800950
## 449  11.12174708 -0.0946837570
## 450   6.10276008  0.0139325353
## 451   8.10350599 -0.0287401251
## 452   5.34975304  0.0176215142
## 453   6.07097817  0.0194857518
## 454  10.18372660 -0.0677885532
## 455   0.26513294  0.1223899401
## 456   5.61977979  0.0233167013
## 457  12.00927872 -0.1157299739
## 458   6.57916498  0.0049052031
## 459  17.61116505 -0.2298889160
## 460   8.31862687 -0.0328695115
## 461  21.37719091 -0.3009850184
## 462   5.91821522  0.0074094025
## 463  12.86612453 -0.1253825873
## 464   9.43831242 -0.0661040728
## 465   4.53394043  0.0505313140
## 466   6.93184549 -0.0095349297
## 467   4.71488218  0.0375113010
## 468   0.81932616  0.1309105158
## 469   9.09667635 -0.0982161760
## 470  -3.18148547  0.2003037333
## 471  10.96527537 -0.0863807576
## 472   5.21740408  0.0170447701
## 473   9.62025984 -0.0612599951
## 474   9.56095732 -0.0495640530
## 475  10.44323060 -0.0680763798
## 476   5.73035846  0.0099553682
## 477   6.09588668  0.0129870304
## 478   4.29509775  0.0470671152
## 479  28.59531959 -0.4463102023
## 480  12.30321240 -0.1238892440
## 481   9.44960609 -0.0696550210
## 482   4.54524409  0.0425837427
## 483  12.18912987 -0.1159609407
## 484   7.32780719 -0.0091736666
## 485  22.48792458 -0.3242150942
## 486   7.62598991 -0.0121397972
## 487  12.45358815 -0.1152178100
## 488   7.24398374 -0.0097362805
## 489  -1.62902594  0.1663208008
## 490   3.90998141  0.0649854872
## 491   6.14365143  0.0128931778
## 492   2.24367591  0.0850500862
## 493  12.37249222 -0.1135013819
## 494   5.63456482  0.0119034680
## 495   3.96696951  0.0561545306
## 496   4.56503735  0.0595803420
## 497  20.21200653 -0.2698980371
## 498   7.92598361 -0.0318025803
## 499   6.32524900  0.0077424197
## 500   6.87643322 -0.0069746077
## 501   8.88791583 -0.0490591764
## 502  11.46699354 -0.1043371624
## 503   4.91075084  0.0485890731
## 504   7.57999844 -0.0172416115
## 505  11.10909147 -0.0800229073
## 506   8.74556712 -0.0422568348
## 507   5.91552889  0.0113555483
## 508  -0.86962941  0.1514579549
## 509  17.84278948 -0.2283483814
## 510  18.34698685 -0.2238617738
## 511   7.25112478 -0.0166716350
## 512  14.57369529 -0.1659575045
## 513   4.58115530  0.0293292602
## 514   7.71152941 -0.0163611964
## 515  15.79147567 -0.1987734092
## 516   7.98451653 -0.0218320771
## 517   5.96971526 -0.0005814268
## 518  -6.26251998  0.2474723229
## 519   8.39838071 -0.0471062814
## 520   5.90182766  0.0135412160
## 521  12.20569786 -0.1053455252
## 522   9.91217905 -0.0753615921
## 523   5.20835639  0.0263677258
## 524   4.24010870  0.0463685480
## 525   9.25098316 -0.0584402198
## 526   4.26075817  0.0407192183
## 527  23.15354633 -0.3309280872
## 528   6.93631742 -0.0130617452
## 529   3.26448415  0.0822478008
## 530  10.39636404 -0.0685255462
## 531  18.38175115 -0.2331703481
## 532   5.17529438  0.0209427223
## 533   8.90018115 -0.0500647881
## 534   5.88388530  0.0022038619
## 535  10.90661860 -0.1004407406
## 536  12.47530690 -0.1108392267
## 537  -6.64501458  0.2700758164
## 538   4.36422888  0.0510407421
## 539  22.23496992 -0.3109824096
## 540  19.98490100 -0.2730317911
## 541  14.11669950 -0.1501679561
## 542   4.32070745  0.0532403623
## 543  12.36528380 -0.1084601879
## 544   6.95083427            NA
## 545   8.43781325 -0.0291832175
## 546   7.09440797 -0.0049765775
## 547   6.94221410 -0.0028446042
## 548   3.72747374  0.0649230480
## 549  -4.33697534  0.2046508392
## 550  11.00994444 -0.0850400329
## 551   3.69542634  0.0680597944
## 552   6.08801304  0.0133693732
## 553   7.46041165 -0.0304560338
## 554   7.24012912 -0.0255555810
## 555  -2.57667470  0.2082240582
## 556  14.66042986 -0.1568219720
## 557   4.71773281  0.0381139020
## 558  11.66696796 -0.1112348557
## 559   9.97475338 -0.0732393742
## 560   6.37397756  0.0011285588
## 561   9.62897603 -0.0620719704
## 562   5.59800343  0.0270878757
## 563   6.99869946 -0.0035039308
## 564   6.32656068  0.0117652279
## 565   7.28004820 -0.0021512022
## 566   5.95203567  0.0184433444
## 567   5.87740278  0.0010729074
## 568  12.37117984 -0.1189004458
## 569  12.68324943 -0.1166268657
## 570   2.39813161  0.0762725702
## 571  10.44079658 -0.0731799603
## 572   5.10175308  0.0248796184
## 573   6.36191432 -0.0003796021
## 574   3.40707397  0.0666524172
## 575  17.50132291 -0.2303982576
## 576   5.09786363  0.0270898690
## 577   5.55043369  0.0136923353
## 578   6.27353060  0.0077457810
## 579   9.33355094 -0.0618374410
## 580   7.10875209 -0.0112521289
## 581   7.14059202 -0.0040943401
## 582   4.82942063  0.0364447097
## 583  11.31140934 -0.0963161321
## 584  14.12877497 -0.1516681612
## 585   9.08819412 -0.0461771418
## 586   6.14986290 -0.0049515837
## 587  18.42040814 -0.2355876810
## 588  19.79198694 -0.2738029559
## 589  14.94934982 -0.1723621090
## 590  10.00994382 -0.0765183926
## 591   6.02328124  0.0143130497
## 592   6.37168215  0.0085591270
## 593   5.18969606  0.0081093592
## 594   9.44404800 -0.0574400783
## 595  13.83281164 -0.1549571262</code></pre>
<p>Le résultat des estimations (g_i) peut alors être introduit dans la fonction <strong>pooltest()</strong> avec le résultat de l’estimation du modèle de pooling (g) pour réaliser le test.</p>
<pre class="r"><code>pooltest(g, g_i)</code></pre>
<pre><code>## 
##  F statistic
## 
## data:  lwage ~ wks
## F = 9.9386, df1 = 1188, df2 = 2975, p-value &lt; 2.2e-16
## alternative hypothesis: unstability</code></pre>
<p>Le test rejette clairement l’hypothèse d’égalité de coefficients (de stabilité). Le modèle de pooling est donc inconsistant. Le même résultat peut être obtenu (plus rapidement) à partir d’une syntaxe incluant la spécification des modèles testés en lieu est place des objets associés à leur estimation.</p>
<pre class="r"><code>pooltest(lwage~wks,data=wages,index=&#39;id&#39;, model = &quot;within&quot;)</code></pre>
<pre><code>## 
##  F statistic
## 
## data:  lwage ~ wks
## F = 1.7654, df1 = 594, df2 = 2975, p-value &lt; 2.2e-16
## alternative hypothesis: unstability</code></pre>
<p>Le graphe ci-contre résume bien la situation. Y sont repris de le nuage de point et la droit du modèle de pooling mais aussi une dizaine d’autres droites (tirées au hasard) dont les paramètres sont issus des estimations individuelles.</p>
<pre class="r"><code>ggplot(data=wages,aes(x=wks,y=lwage))+
  geom_point()+
  geom_abline(slope=g_i$coefficients[5,2],
              intercept = g_i$coefficients[5,1],color=&#39;blue&#39;)+
  geom_abline(slope=g_i$coefficients[55,2],
              intercept = g_i$coefficients[55,1],color=&#39;blue&#39;)+
  geom_abline(slope=g_i$coefficients[555,2],
              intercept = g_i$coefficients[555,1],color=&#39;blue&#39;)+
  geom_abline(slope=g_i$coefficients[366,2],
              intercept = g_i$coefficients[366,1],color=&#39;blue&#39;)+
  geom_abline(slope=g_i$coefficients[70,2],
              intercept = g_i$coefficients[70,1],color=&#39;blue&#39;)+
  geom_abline(slope=g_i$coefficients[66,2],
              intercept = g_i$coefficients[66,1],color=&#39;blue&#39;)+
  geom_abline(slope=g_i$coefficients[8,2],
              intercept = g_i$coefficients[8,1],color=&#39;blue&#39;)+
  geom_abline(slope=g_i$coefficients[28,2],
              intercept = g_i$coefficients[28,1],color=&#39;blue&#39;)+
  geom_abline(slope=g_i$coefficients[82,2],
              intercept = g_i$coefficients[82,1],color=&#39;blue&#39;)+
  geom_abline(slope=g_i$coefficients[43,2],
              intercept = g_i$coefficients[43,1],color=&#39;blue&#39;)+
  geom_smooth(method = &quot;lm&quot;,color=&#39;red&#39;,se=FALSE)+
  coord_cartesian(expand=FALSE,xlim=c(4,53),ylim=c(4.5,8.7))+
  theme_minimal()</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>La droite en rouge résume difficilement l’information contenue dans les droites en bleu.</p>
<p>Un second test permet de confirmer l’existence d’un problème de variables manquantes et donc la présence d’effets à contrôler. Celui-ci est basé sur le multiplicateur de Lagrange. Il s’agit d’évaluer l’hypothèse nulle postulant que la variance inter- individus (ou période) est nulle et donc qu’il n’y a pas d’effet de panel. Le test est réalisé à partie de la fonction <strong>plmtest()</strong> de <em>plm</em>. Il suffit d’indiquer le modèle de pooling (ou son équation) et le type de procédure retenue. Ici, nous utiliserons la version la plus ancienne Breusch-Pagan (bp).</p>
<pre class="r"><code>plmtest(g, type=c(&quot;bp&quot;))</code></pre>
<pre><code>## 
##  Lagrange Multiplier Test - (Breusch-Pagan) for balanced panels
## 
## data:  lwage ~ wks
## chisq = 5792.8, df = 1, p-value &lt; 2.2e-16
## alternative hypothesis: significant effects</code></pre>
<p>L’hypothèse d’absence d’effets de panel à prendre en compte est largement rejetée. Ce test est généralement doublé d’un second permettant de comparer le modèle de pooling (MCO simple) avec le modèle à effets fixes (“within”). La fonction <strong>pFtest()</strong> permet de le mettre en oeuvre en suivant la même type syntaxe. On peut soit indiqué les modèles à comparer avec le modèle “within” en premier et le modèle de pooling en second ou juste l’indication du premier.</p>
<pre class="r"><code>pFtest(lwage~wks, data=wages,index=&#39;id&#39;, effect=&quot;individual&quot;)</code></pre>
<pre><code>## 
##  F test for individual effects
## 
## data:  lwage ~ wks
## F = 16.065, df1 = 594, df2 = 3569, p-value &lt; 2.2e-16
## alternative hypothesis: significant effects</code></pre>
<p>Ici aussi, l’hypothèse d’absence d’effets à prendre en compte est rejetée. Le modèle à effets fixes apparaît meilleur que le modèle de pooling.</p>
<p>Dans les deux cas, H0 est rejetée. Il y a bien un effet de panel. Il reste alors à déterminer qu’elle type d’effets retenir: fixes ou aléatoire.</p>
<p>Estimons les deux et procédons à un test de Durbin–Wu–Hausman afin de déterminer le plus pertinent.</p>
<p>Commençons par le modèle à effets aléatoires.</p>
<p><span class="math display">\[y_{it}=\alpha+\beta_{1}.x_{it}+\mu_i+u_{it}\]</span></p>
<p>La variabilité intra individuelle est intégrée au terme d’erreur. Il est pour cela nécessaire que l’effet soit à la fois indépendant de la variable explicative et du terme d’erreur du modèle. D’un point de vue pratique, pour l’estimer, il suffit d’utiliser la fonction <strong>plm()</strong> et de préciser “random” dans l’option model.</p>
<pre class="r"><code>alea&lt;-plm(lwage ~ wks, data=wages, index=c(&quot;id&quot;),model=&quot;random&quot;)
alea %&gt;% tidy()</code></pre>
<pre><code>## # A tibble: 2 × 5
##   term        estimate std.error statistic p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept)  6.61      0.0495     134.     0    
## 2 wks          0.00144   0.00100      1.44   0.150</code></pre>
<p>La spécification générale associée aux effets fixes individuels est la suivante:</p>
<p><span class="math display">\[y_{it}=\alpha_i+\beta_{1}.x_{it}+u_{it}\]</span></p>
<p>La variabilité intra individuelle est prise en compte en faisant varier l’ordonnée à l’origine de modèle. On n’a ainsi un bêta fixe et un alpha différent selon l’individu considéré. Pour l’estimer, il suffit d’utiliser la fonction <strong>plm()</strong> et de préciser “within” dans l’option model.</p>
<pre class="r"><code>wit&lt;-plm(lwage ~ wks, data=wages, index=c(&quot;id&quot;),model=&quot;within&quot;)
wit %&gt;% tidy()</code></pre>
<pre><code>## # A tibble: 1 × 5
##   term  estimate std.error statistic p.value
##   &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 wks    0.00101   0.00102     0.988   0.323</code></pre>
<p>Le test est réalisé à partir de la fonction <strong>phtest()</strong> en intégrant les noms des modèles à comparer.</p>
<pre class="r"><code>phtest(wit,alea)</code></pre>
<pre><code>## 
##  Hausman Test
## 
## data:  lwage ~ wks
## chisq = 4.3878, df = 1, p-value = 0.0362
## alternative hypothesis: one model is inconsistent</code></pre>
<p>Le modèle à effet aléatoire est diagnostiqué comme inconsistant. Le modèle à effet fixe apparaît ici comme le meilleur. Mais en quoi consiste-t-il au juste?</p>
<p>Dans sa version la plus simple, il s’agit d’une estimation par les MCO d’un modèle incluant une variable indicatrice par individu (id). Ici, on aura donc 595 variables binaire supplémentaire (moins une si on garde la constante dans le modèle).</p>
<pre class="r"><code>dum_mod&lt;-lm(lwage~wks+factor(id)-1,data=wages) 
dum_mod%&gt;% tidy()</code></pre>
<pre><code>## # A tibble: 596 × 5
##    term        estimate std.error statistic p.value
##    &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
##  1 wks          0.00101   0.00102     0.988   0.323
##  2 factor(id)1  5.93      0.105      56.3     0    
##  3 factor(id)2  6.47      0.103      62.6     0    
##  4 factor(id)3  6.46      0.111      58.3     0    
##  5 factor(id)4  6.34      0.110      57.8     0    
##  6 factor(id)5  6.86      0.109      62.8     0    
##  7 factor(id)6  7.05      0.109      64.8     0    
##  8 factor(id)7  6.26      0.109      57.3     0    
##  9 factor(id)8  6.54      0.110      59.3     0    
## 10 factor(id)9  6.85      0.110      62.4     0    
## # … with 586 more rows</code></pre>
<p>Si cette version permet bien de contrôler des effets fixes individuels et donc de l’inobservable variant en fonction de l’individu et pas dans le temp, elle reste laborieuse à manipuler. Aussi, il existe une alternative plus pratique produisant le même résultat sans les variables indicatrice individuelles : le modèle “within”. Il s’agit de transformer les variables en leur soustrayant leur moyenne calculé sur une base individuel et d’appliquer les MCO sur le résultat de la transformation. On a ainsi:</p>
<p><span class="math display">\[(y_{it}-\bar{y_i})=\alpha_i+\beta_{1}.(x_{it}-\bar{x_i})+u_{it}\]</span></p>
<p>Réalisons la transformation within sur nos données.</p>
<pre class="r"><code>wi_d&lt;-wages %&gt;% group_by(id) %&gt;% 
  mutate(m_lwage=mean(lwage),m_wks=mean(wks),
         w_lwage=lwage-m_lwage,w_wks=wks-m_wks)</code></pre>
<p>Estimons le modèle à partir de la fonction <strong>lm()</strong>.</p>
<pre class="r"><code>w_l&lt;-lm(w_lwage~w_wks-1,data=wi_d)
w_l %&gt;% tidy()</code></pre>
<pre><code>## # A tibble: 1 × 5
##   term  estimate std.error statistic p.value
##   &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 w_wks  0.00101  0.000945      1.07   0.286</code></pre>
<p>On retrouve bien le même coefficient estimé que dans la version intégrant les variables indicatrices individuelles et dans celle générée à partir de <strong>plm(.,model=“within”)</strong>. Par contre, l’erreur standard est différente. Voyons ce qu’il en est. Commençons par recalculer en détaillant les différentes étapes la statistique pour nos différents modèle.</p>
<p>Voyons d’abord par le dernière modèle. Mais avant, un petit rappel. Le point de départ pour obtenir l’erreur standard des coefficients est la matrice variance covariance du modèle (<span class="math inline">\(var(\hat{\beta})\)</span>).</p>
<p><span class="math display">\[VAR(\hat{\beta})=\hat{\sigma}^2.(X&#39;.X)^{-1}\]</span></p>
<p>Celle-ci est diagonalisée et passée à la racine carrée.</p>
<p><span class="math display">\[s.e.(\hat{\beta})=\sqrt{diag(VAR(\hat{\beta}))}\]</span></p>
<p>La fonction <strong>vcoc()</strong> permet d’obtenir la matrice à partir du modèle.</p>
<pre class="r"><code>vcov(w_l)</code></pre>
<pre><code>##              w_wks
## w_wks 8.929782e-07</code></pre>
<p>Mais on peut aussi détailler le calcul permettant d’obtenir ce résultat</p>
<pre class="r"><code>invXtX &lt;- solve(crossprod(wi_d$w_wks))
(sum(w_l$residuals^2)/(w_l$df.residual))*invXtX</code></pre>
<pre><code>##              [,1]
## [1,] 8.929782e-07</code></pre>
<p>Reste à diagonaliser et passer l’ensemble à la racine carré.</p>
<pre class="r"><code>sqrt(diag(vcov(w_l)))</code></pre>
<pre><code>##        w_wks 
## 0.0009449752</code></pre>
<p>On retrouve bien notre erreur standard. Voyons ce qu’il en est avec les deux autres modèles.</p>
<pre class="r"><code>c(sqrt(diag(vcov(wit))),sqrt(diag(vcov(dum_mod)))[1])</code></pre>
<pre><code>##        wks        wks 
## 0.00102071 0.00102071</code></pre>
<p>Nous avons retrouvons bien les mêmes erreurs standards. Ceci étant posé, il nous reste à comprendre comment le modèle “within” ajuste les choses pour produire la même valeur le modèle à variables indicatives. En fait, il va ajuster sa matrice variance covariance de manière à ce que les mêmes restrictions en matière de degrés de liberté des résidus soit considéré. Pour rappel, dans le modèle dum_mod nous avons un paramètre par individu donc 595 et un paramètre pour wks. On a donc 4165-596 degrés de liberté soit 3569.</p>
<pre class="r"><code>invXtX&lt;-solve(crossprod(wi_d$w_wks))
var_b&lt;-(sum(w_l$residuals^2)/(3569))*invXtX
sqrt(diag(var_b))</code></pre>
<pre><code>## [1] 0.00102071</code></pre>
<p>Bon voilà, je pense que ce premier poste est déjà assez long. (suite au prochain numéro…)</p>
